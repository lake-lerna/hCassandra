{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hCassandra runTests\n",
    "\n",
    "## Description\n",
    "\n",
    "---\n",
    "\n",
    "### Objective\n",
    "\n",
    "   This test aims to **automate**:\n",
    "   \n",
    "   (1) The execution of the Hydra Cassandra Stress Test (hCassandra) for increasing client load.\n",
    "   \n",
    "   (2) The generation of performance results presented in the form of tables and graphs for relevant metrics. \n",
    "   \n",
    "   To this end, performance of the Cassandra Cluster is measured as the number of clients writing and reading into the DataBase is increased. The number of clients can be defined by the user. \n",
    "   \n",
    " \n",
    "### Customize the Test\n",
    "\n",
    "   Modify **total_num_clients** to change the sets of clients for which you wish to execute the test.\n",
    "   \n",
    "   Current tests have been run for a maximum of **10000** clients and a duration of 5 minutes against a 3-node Cluster (for further details on Software & Hardware specs please refer to the *Software & Hardware Specs* section).\n",
    "   \n",
    "### Useful HINTS for running the test\n",
    "\n",
    "- If test has been previously executed and output is still shown, you can restart (delete former results) by selecting in the top menu Cell -> All Output -> Clear\n",
    "- To run test, step on top of the code cells and press the 'run cell' button on the top menu. For automatic Run select from the top menu Cell -> Run All\n",
    "- If you wish to store your results. After RUN is finished, generate your own report by selecting FILE -> Download as -> Markdown (.md) (or any other preferred format)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software & Hardware Specs\n",
    "\n",
    "---\n",
    "\n",
    "The tests were executed on Google Cloud Servers, with the following specs:\n",
    "\n",
    "#### Cassandra Cluster\n",
    "\n",
    "- 3 Node Cluster, each with the following specs:\n",
    "   - 16 vCPUs\n",
    "   - RAM: 60 GB\n",
    "   - Disk: 60 GB\n",
    "   - OS: Debian 3.16.7-ckt25-2\n",
    "  \n",
    "- Cassandra + Cassandra-Tools Version: 3.0.6\n",
    "\n",
    "#### Hydra Cluster\n",
    "\n",
    "- **MASTER**: 1 Server\n",
    "   - 4 vCPUs\n",
    "   - RAM: 15 GB\n",
    "   - OS: Ubuntu 14.04\n",
    "\n",
    "- **SLAVES**: 9 Servers (hosts to the cassandra-stress tool)\n",
    "   - 16 vCPUs \n",
    "   - RAM: 60 GB\n",
    "   - Disk: 60 GB\n",
    "   - OS: Debian 3.16.7-ckt25-2\n",
    "   \n",
    "### Important \n",
    "\n",
    "- For the performance tests maximum file open limit (ulimit) had to be increased for the Master Node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## hCassandra Test 1: Fixed Number of Stress Clients (Debug Mode) \n",
    "\n",
    "---\n",
    "\n",
    "The following test runs a SINGLE execution of the Cassandra Test for a fixed number of clients (total_client_count) and operations (total_ops_count). Runs in debug mode: showing logger info during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python ./src/hCassandra_test.py --cluster_ips='10.10.1.108,10.10.1.165,10.10.1.162' --total_client_count=20 --total_ops_count=1000 --test_duration=5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## hCassandra Test 2: Increasing the Number of stress clients (multiple runs)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**IMPORTANT**:\n",
    "\n",
    "   If you want to change the number of clients and/or number of operations for your test, please set values to desired in the following section:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define num Client(s) / Operation(s)\n",
    "total_num_clients = [10, 100, 200, 400, 800, 1600, 3200, 5000, 6000, 7000, 8000]\n",
    "duration_array = [5, 10, 10, 10, 10, 20, 40, 60, 60, 70, 80]\n",
    "total_ops_count = [1000000]\n",
    "simulate_failure = False\n",
    "# Set IPs of Nodes in Cassandra Cluster\n",
    "cassandra_cluster_ips = '10.10.1.108,10.10.1.165,10.10.1.162'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UTIL FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "def get_result(test_stdout):\n",
    "    \"\"\"This Function gets (filters) the Cassandra Test Results from stdout\"\"\"\n",
    "    index_start = test_stdout.find('Cassandra Stress Results: \\n')\n",
    "    index_end = test_stdout.find('Calling Server shutdown')\n",
    "    if index_start != -1:\n",
    "        results = test_stdout[(index_start + len('Cassandra Stress Results: \\n')):index_end]\n",
    "        res_dict = ast.literal_eval(results)\n",
    "        return res_dict\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block of code is the actual **EXECUTION OF THE CASSANDRA SCALE TESTS**. This may take a couple of minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "import signal\n",
    "\n",
    "hCassandra_results = dict()\n",
    "\n",
    "print 'STARTING CASSANDRA STRESS TESTS \\n'\n",
    "# Execute hCassandra_test for given client_count\n",
    "for idx1, clients in enumerate(total_num_clients):\n",
    "    for idx2, ops in enumerate(total_ops_count):\n",
    "        print ('Test (%s/%s) in progress.. Please wait until test is completed..' % ((len(total_ops_count) * idx1) + idx2 + 1,len(total_num_clients) * len(total_ops_count)))\n",
    "        # Execute hCassandra_test.py (python script for hCassandra Scale Test)\n",
    "        if simulate_failure:\n",
    "            hcass_cmd = \"python ./src/hCassandra_test.py --cluster_ips=%s --total_client_count=%s --total_ops_count=%s --test_duration=%s\" % (cassandra_cluster_ips, clients, ops, duration_array[idx1])\n",
    "        else:\n",
    "            hcass_cmd = \"python ./src/hCassandra_test.py --cluster_ips=%s --total_client_count=%s --total_ops_count=%s --test_duration=%s\" % (cassandra_cluster_ips, clients, ops, duration_array[idx1])\n",
    "        stress_test = subprocess.Popen(hcass_cmd, stdout=subprocess.PIPE,\n",
    "                                          stderr=subprocess.PIPE, shell=True, preexec_fn=os.setsid)\n",
    "        stdout, stderr = stress_test.communicate()\n",
    "        results_dict = get_result(stdout)\n",
    "        if len(results_dict) <= 1:\n",
    "            print ('There was an ERROR while attempting to parse stdout...')\n",
    "            print 'STDOUT: %s' % stdout\n",
    "            print 'STDERR: %s' % stderr\n",
    "        if not str(clients) in hCassandra_results:\n",
    "            hCassandra_results[str(clients)] = dict()\n",
    "        hCassandra_results[str(clients)][str(ops)] = results_dict\n",
    "        with open('results_hcassandra.txt', 'w') as outfile:\n",
    "            json.dump(hCassandra_results, outfile)\n",
    "        print 'Test SUCCESFULLY completed... \\n'\n",
    "\n",
    "print 'END OF TESTS:'\n",
    "print 'ALL TESTS HAVE BEEN COMPLETED. PLEASE PROCEED TO GENERATE GRAPHS & TABLES WITH PERFORMANCE RESULTS.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "  **NOTE:**\n",
    "  \n",
    "  ---\n",
    "   \n",
    "   Wait until RESULTS (**hCassandra_results**) are generated for all cases, and then execute the following blocks to generate:\n",
    "   (1) Tables with results (markdown compatible) and \n",
    "   (2) Graphs.\n",
    "   \n",
    "   The **END OF TEST** is indicated by a message. Please wait...\n",
    "   \n",
    "   ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULT PROCESSING & TABLE/ GRAPH GENERATION\n",
    "\n",
    "---\n",
    "\n",
    "In this section, we process the results for generating tables with performance values and graphs that reflect number of operations per second and median latency for increased number of clients. \n",
    "\n",
    "**NOTE**\n",
    "If you are interested in representing any other performance metric, follow the pattern followed for any of the two graps already provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persist results to *results_hcassandra.txt* file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('results_hcassandra.txt', 'w') as outfile:\n",
    "    json.dump(hCassandra_results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following object converts a list to an HTML formatted table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ListTable(list):\n",
    "    \"\"\" Overridden list class which takes a 2-dimensional list of \n",
    "        the form [[1,2,3],[4,5,6]], and renders an HTML Table in \n",
    "        IPython Notebook. \"\"\"\n",
    "    \n",
    "    def _repr_html_(self):\n",
    "        html = [\"<table>\"]\n",
    "        for row in self:\n",
    "            html.append(\"<tr>\")\n",
    "            \n",
    "            for col in row:\n",
    "                html.append(\"<td>{0}</td>\".format(col))\n",
    "            \n",
    "            html.append(\"</tr>\")\n",
    "        html.append(\"</table>\")\n",
    "        return ''.join(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process and format results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "results_per_ops = dict()\n",
    "\n",
    "# Table Format: Metrics\n",
    "header = [\n",
    "            '# Clients',\n",
    "            'total_ops',\n",
    "            'op/s',\n",
    "            'med',\n",
    "            '.95',\n",
    "            '.99',\n",
    "            'max',\n",
    "            'op_time'\n",
    "        ]\n",
    "\n",
    "data_matrix_write = ListTable()\n",
    "data_matrix_read = ListTable()\n",
    "\n",
    "data_matrix_write.append(header)\n",
    "data_matrix_read.append(header)\n",
    "\n",
    "results_per_ops[str(total_ops_count[0])] = dict()\n",
    "for idx1, clients in enumerate(total_num_clients):\n",
    "    if str(clients) in hCassandra_results:\n",
    "        res_dict = ast.literal_eval(hCassandra_results[str(clients)][str(total_ops_count[0])])\n",
    "        if (('op/s' in res_dict['write']) and ('op/s' in res_dict['read'])): \n",
    "            if ((len(res_dict['write']['op/s']) !=0) and (len(res_dict['read']['op/s']) !=0)):\n",
    "                results_per_ops[str(total_ops_count[0])][str(clients)] = res_dict\n",
    "                data_matrix_write.append([clients, sum((ops for ops in res_dict['write']['total ops'])), sum((ops for ops in res_dict['write']['op/s'])), numpy.median(res_dict['write']['med']), numpy.percentile(res_dict['write']['.95'], 95), numpy.percentile(res_dict['write']['.99'], 99), max(res_dict['write']['max']), res_dict['write']['op_time'][0]])\n",
    "                data_matrix_read.append([clients, sum((ops for ops in res_dict['read']['total ops'])), sum((ops for ops in res_dict['read']['op/s'])), numpy.median(res_dict['read']['med']), numpy.percentile(res_dict['read']['.95'], 95), numpy.percentile(res_dict['read']['.99'], 99), max(res_dict['read']['max']), duration_array[idx1]])   \n",
    "            else:\n",
    "                if (len(res_dict['write']['op/s']) !=0):\n",
    "                    data_matrix_write.append([clients, sum((ops for ops in res_dict['write']['total ops'])), sum((ops for ops in res_dict['write']['op/s'])), numpy.median(res_dict['write']['med']), numpy.percentile(res_dict['write']['.95'], 95), numpy.percentile(res_dict['write']['.99'], 99), max(res_dict['write']['max']), res_dict['write']['op_time'][0]])\n",
    "                elif (len(res_dict['read']['op/s']) !=0):\n",
    "                    data_matrix_read.append([clients, sum((ops for ops in res_dict['read']['total ops'])), sum((ops for ops in res_dict['read']['op/s'])), numpy.median(res_dict['read']['med']), numpy.percentile(res_dict['read']['.95'], 95), numpy.percentile(res_dict['read']['.99'], 99), max(res_dict['read']['max']), duration_array[idx1]])   \n",
    "                else:\n",
    "                    print (\"Removing Results for client count %s. No results found.\" % clients)\n",
    "        else:\n",
    "            print (\"Removing Results for client count %s. No results found.\" % clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Generation: Table\n",
    "\n",
    "Next, results are displayed in a Table, following the markdown format. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results for 'WRITE' operation in a file. This will be a backup of test results in case of failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "text_file = open(\"write_stats_\" + str(datetime.now().strftime(\"%m%d%Y_%H%M%S\")) + \".txt\", \"w\")\n",
    "text_file.write(\"%s\" % data_matrix_write)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next table represents the results for the **WRITE** Operations:\n",
    "\n",
    "---\n",
    "\n",
    "*Table 1. \"Cassandra Performance over WRITE Operation.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_matrix_write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next table represents the results for the **READ** Operations:\n",
    "\n",
    "---\n",
    "\n",
    "*Table 2. \"Cassandra Performance over READ Operation.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_file = open(\"read_stats_\" + str(datetime.now().strftime(\"%m%d%Y_%H%M%S\")) + \".txt\", \"w\")\n",
    "text_file.write(\"%s\" % data_matrix_read)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_matrix_read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Generation: Graphs\n",
    "\n",
    "Next, results are displayed in Graphs. \n",
    "\n",
    "--- \n",
    "\n",
    "**IMPORTANT**\n",
    "\n",
    "Please, MODIFY the graphs name here if desired. Otherwise, graphs are indexed by datetime. \n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "ops_second_graph_filename = \"hCassandra_ops_\" + str(datetime.now().strftime(\"%m%d%Y_%H%M%S\"))\n",
    "median_latency_graph_filename = \"hCassandra_med_\" + str(datetime.now().strftime(\"%m%d%Y_%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def asint(s):\n",
    "    try: return int(s), ''\n",
    "    except ValueError: return sys.maxint, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "import operator\n",
    "import numpy\n",
    "import collections\n",
    "\n",
    "# run at the start of every ipython notebook to use plotly.offline\n",
    "offline.init_notebook_mode(connected=True)\n",
    "\n",
    "data_matrix = [['# ops', '# Clients', 'total_ops', 'op/s', 'pk/s', 'med', '.95', '.99', 'max', 'max_ms', 'sdv_ms', 'op_time']]\n",
    "\n",
    "traces_plot1 = []\n",
    "traces_plot2 = []\n",
    "\n",
    "# For each trace = client count\n",
    "for ops_count, tests_per_trace in results_per_ops.iteritems():\n",
    "    \n",
    "    total_ops = []\n",
    "    op_s = []\n",
    "    op_s_r = []\n",
    "    med = []\n",
    "    med_r = []\n",
    "    p99 = []\n",
    "    p99_r = []\n",
    "    max_lat = []\n",
    "    max_lat_r = []\n",
    "    \n",
    "    clients = []\n",
    "    # Sort list by # Clients\n",
    "    sortedlist = [(k, tests_per_trace[k]) for k in sorted(tests_per_trace, key=asint)]\n",
    "    \n",
    "    for test in sortedlist:\n",
    "        clients.append(test[0])\n",
    "        op_s.append(sum((ops for ops in test[1]['write']['op/s'])))\n",
    "        med.append(numpy.median(test[1]['write']['med']))\n",
    "        op_s_r.append(sum((ops for ops in test[1]['read']['op/s'])))\n",
    "        med_r.append(numpy.median(test[1]['read']['med']))\n",
    "        p99.append(numpy.percentile(test[1]['write']['.99'], 99))\n",
    "        p99_r.append(numpy.percentile(test[1]['read']['.99'], 99))\n",
    "        max_lat.append(max(test[1]['write']['max']))\n",
    "        max_lat_r.append(max(test[1]['read']['max']))\n",
    "        \n",
    "    trace_plot1 = Scatter(\n",
    "          x=clients,\n",
    "          y=op_s, \n",
    "          mode = 'lines+markers',\n",
    "          name = 'WRITE',\n",
    "          marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgb(91,79,224)')\n",
    "        )\n",
    "    \n",
    "    trace_plot2 = Scatter(\n",
    "          x=clients,\n",
    "          y=op_s_r, \n",
    "          mode = 'lines+markers',\n",
    "          name = 'READ',\n",
    "          marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgb(212,224,79)')\n",
    "        )\n",
    "        \n",
    "    trace_plot3 = Scatter(\n",
    "          x=clients,\n",
    "          y=med, \n",
    "          mode = 'lines+markers',\n",
    "          name = 'WRITE-median', \n",
    "          marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgb(91,79,224)')\n",
    "        )\n",
    "\n",
    "    trace_plot4 = Scatter(\n",
    "          x=clients,\n",
    "          y=med_r, \n",
    "          mode = 'lines+markers',\n",
    "          name = 'READ-median', \n",
    "          marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgb(212,224,79)')\n",
    "        )\n",
    "    trace_plot5 = Scatter(\n",
    "          x=clients,\n",
    "          y=p99, \n",
    "          mode = 'lines+markers',\n",
    "          name = 'WRITE-percentile 99', \n",
    "          marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgb(222,44,118)')\n",
    "        )\n",
    "    trace_plot7 = Scatter(\n",
    "          x=clients,\n",
    "          y=max_lat, \n",
    "          mode = 'lines+markers',\n",
    "          name = 'WRITE-max', \n",
    "          marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgb(29,113,204)')\n",
    "        )\n",
    "    trace_plot8 = Scatter(\n",
    "          x=clients,\n",
    "          y=p99_r, \n",
    "          mode = 'lines+markers',\n",
    "          name = 'READ-percentile 99', \n",
    "          marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgb(255,151,5)')\n",
    "        )\n",
    "    trace_plot9 = Scatter(\n",
    "          x=clients,\n",
    "          y=max_lat_r, \n",
    "          mode = 'lines+markers',\n",
    "          name = 'READ-max', \n",
    "          marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgb(36,218,242)')\n",
    "        )\n",
    "    \n",
    "    traces_plot1.append(trace_plot1)\n",
    "    traces_plot1.append(trace_plot2)\n",
    "    traces_plot2.append(trace_plot3)\n",
    "    traces_plot2.append(trace_plot4)\n",
    "    traces_plot2.append(trace_plot5)\n",
    "    traces_plot2.append(trace_plot7)\n",
    "    traces_plot2.append(trace_plot8)\n",
    "    traces_plot2.append(trace_plot9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Generation: operations per second vs. client count\n",
    "\n",
    "The following graph illustrates how, the number of operations per second changes while the number of clients increases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture plot_med --no-stdout\n",
    "\n",
    "data = Data(traces_plot1)\n",
    "# Edit the layout\n",
    "layout = dict(title = 'op/s vs. # Clients',\n",
    "              xaxis = dict(title = '# clients'),\n",
    "              yaxis = dict(title = 'op/s'),\n",
    "              )\n",
    "\n",
    "# Plot and embed in notebook\n",
    "fig = dict(data=data, layout=layout)\n",
    "offline.plot(fig, filename=ops_second_graph_filename + \"_offline\")\n",
    "py.iplot(fig, filename = ops_second_graph_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Generation: median latency vs. client count\n",
    "\n",
    "The following graph illustrates median latency in miliseconds for each operation during that run as the number of clients increases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture plot_med --no-stdout\n",
    "\n",
    "data = Data(traces_plot2)\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Latency vs. Client Count',\n",
    "              xaxis = dict(title = '# Clients'),\n",
    "              yaxis = dict(type='log', title = 'Latency [ms]'),\n",
    "              )\n",
    "\n",
    "# Plot and embed in notebook\n",
    "fig = dict(data=data, layout=layout)\n",
    "offline.plot(fig, filename = median_latency_graph_filename + \"_offline\")\n",
    "py.iplot(fig, filename = median_latency_graph_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, these benchmarks represent the **maximum throughput** of a 3 node cluster for the *default* model generated by the cassandra-stress tool. For accurate performance assessment of an application a range of parameters (including data model, queries, etc.) need to be adjusted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
